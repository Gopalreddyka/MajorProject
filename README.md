# IMAGE DESCRIPTION FOR VISUALLY IMPAIRED

According to the World Health Organization, around 40 million people are blind, and another 250 million people have some sort of vision impairment. Unfortunately, those with vision impairments typically cannot view images. Our research proposes an approach that can automatically generate audio description of images, which can substantially assist the visually impaired. There are less opportunities for visually impaired people to interact in todayâ€™s environment, so this paper is necessary. The rising digitization of services and advancement in the technology have made their life more complex, using an image describer can be an enabler for blinds. So we developed a web interface in order to assist them. 
         The processed visuals that the visually handicapped cannot see are processed and then a suitable description is generated and outputted as voice. A simplistic web-interface is developed using Streamlit. The paper uses the Inceptionv3 model for the feature extraction. The Transformer encoder-decoder model to extract image characteristics and generate the text description of the image, which is then converted to an audio using Google Text-to-Speech converter. The generated captions must now precisely reflect the image's graphical information and be highly syntactically understandable. BLEU, METEOR, ROUGE L, CIDEr score is used for evaluation after captioning. The results were shown to be more accurate, and as a result, it may help the blind to describe the surrounding around them.        
         
         
# Dataset link
[Coco dataset 2017](https://www.kaggle.com/datasets/awsaf49/coco-2017-dataset)


# Project Drive link 
[drive link ](https://www.kaggle.com/datasets/awsaf49/coco-2017-dataset)


